[TOC]

# 机器学习

## 一、基本概念

### 1. 机器学习分类

1）有监督学习、无监督学习、半监督学习

- 有监督学习：回归、分类
- 无监督学习：聚类

2）批量学习、增量学习

3）基于实例学习、基于模型学习

- 基于实例的学习：决策树
- 基于模型的学习：线性模型、贝叶斯、SVM

### 2. 基本问题

1）回归问题：预测结果为连续值

2）分类问题：预测结果为离散值

3）聚类问题：根据样本的相似度进行类别划分，无监督学习

### 3. 机器学习的一般过程

收集数据 --> 数据清洗 --> 选择模型 --> 训练 --> 评估 --> 测试 --> 应用及维护

## 二、数据预处理

1）标准化：每列均值为0，标准差为1

2）范围缩放：最大值转换为1，最小值转换为0

3）归一化：数值转换为百分比（按行）

4）二值化：将样本特征值转换为0/1两个值

5）独热编码：每个数值都用0/1来表示，可逆

6）标签编码：字符串转换为数字



## 三、回归问题

### 1. 线性回归

1）线性模型：$y = w^Tx + b$

2）线性回归：根据样本分布规律（样本基本呈线性分布），找到一个最优线性模型，用来执行预测

3）如何找到最优模型

- 损失函数：度量预测结果和真实值之间的差异
- 梯度下降：沿梯度（函数上升最快的方向）负方向调整线性模型的系数

### 2. Lasso回归和岭回归

1）Lasso回归：线性回归损失函数增加了L1正则项

2）岭回归：线性回归损失函数增加了L2正则项

### 3. 多项式回归

1）多项式回归：引入高次项，用于样本呈非线性分布情况

2）多项式回归可以理解为线性回归的扩展

3）欠拟合、过拟合

- 欠拟合：模型对数据拟合度不够，没有学习到数据真正分布规律。具体表现为训练集、测试集下准确度都不高
- 过拟合：模型过度拟合于训练样本，导致泛化能力差。具体表现为训练集下准确度较高，测试集/评估集/实际数据中准确度较低
- 解决方法
  - 欠拟合：提高模型复杂度、增加特征
  - 过拟合：降低模型复杂度、减少特征

### 4. 评价指标

1）均方差

2）R2综合系数



## 四、分类问题

### 1. 定义

预测结果是离散的，预测结果之间没有中间值、过渡值

### 2. 逻辑回归

1）定义：二分类问题，先利用回归模型计算，然后由逻辑函数转换为两个值

2）逻辑函数(Sigmoid)：将负无穷到正无穷范围内的数字压缩到0~1之间

3）损失函数：交叉熵，度量两组概率之间的差异

4）二分类问题实现多分类：多个二分类模型

### 3. 决策树

1）定义：利用“同因同果”的原理，将样本划分到树状结构不同的子节点下，每个子节点下样本具有相同的属性，根据求平均值实现回归，根据投票法实现分类

2）结构：根节点（所有样本未划分）；中间节点（判断和决策节点）；叶子节点（样本）

3）信息熵：度量一组数据有序或混乱程度的指标，该值越大，说明系统越混乱（或纯净度越低）；该值越小，说明系统越有序（或纯净度越高）

4）决策树选择属性的依据

- 信息增益：划分类别前、后信息熵差值
- 增益率：划分类别前、后信息熵增益的比率
- 基尼系数

5）决策树枝剪：预枝剪、后枝剪

6）集成学习

- 定义：利用多个模型同时学习训练，客服单个模型缺陷
- 两个系列
  - 强关联：Boosting，代表性算法AdaBoosting
  - 弱关联：Bagging，代表性算法随机森林

### 4. 支持向量机

1）定义：二分类模型，在样本间找一个最优的线性分类边界，使得支持向量到分类边界间隔距离最大化

2）分类边界要求：正确性、公平性、安全性、简单性

3）线性可分与线性不可分

4）核函数：将线性不可分问题转换为线性可分问题

- 线性核函数：不升维，在原空间下寻找分类边界，主要用于线性可分问题
- 多项式核函数：多项式升维
- 径向基核函数：通过高斯核函数升维

### 5. 朴素贝叶斯

1）关于概率的术语

- 随机事件与概率：可能出现、可能不出现的事件称为随机事件，随机事件出现的可能性大小称为概率
- 联合概率：多个随机事件同时出现的概率
- 条件概率：给定某个条件下，某个随机事件的概率
- 事件独立性：事件之间无相互影响
- 先验概率和后验概率：先验概率指没有任何前提情况下的概率；后验概率是给定一定前提下的概率

2）贝叶斯定理
$$
P(A|B) = \frac{P(A)P(B|A)}{P(B)}
$$
3）朴素贝叶斯分类器：假设事件的出现时独立的、无相互影响



## 五、聚类

1）定义：无监督学习，根据样本的相似性，将其划分为不同的聚簇

2）相似度的度量

- 欧氏距离
- 曼哈顿距离
- 切比雪夫距离
- 闵可夫斯基距离：前三者都是本距离的特殊形式

3）聚类算法划分

- 基于原型的聚类
- 基于密度的聚类
- 基于层次的聚类

4）聚类算法

| 比较项                   | K-Means  | DBSCAN   | 凝聚层次 |
| ------------------------ | -------- | -------- | -------- |
| 类别                     | 基于原型 | 基于密度 | 基于层次 |
| 有没有中心               | 有       | 无       | 无       |
| 是否需要提前知道聚类数量 | 是       | 否       | 是       |
| 噪声样本是否敏感         | 敏感     | 不敏感   | 不敏感   |

## 六、模型评估与优化

1）性能度量（分类）

- 查准率：分类准不准
- 召回率（查全率）：分类全不全
- F1综合得分：分类问题查准率、召回率综合指标
- 混淆矩阵

2）训练集、测试集划分

3）交叉验证：将数据划分为N个折叠，每次将其中的一个作为测试集，其它的作为训练集，克服了因为训练集、测试集划分不当对模型的影响

4）验证曲线和学习曲线

- 验证曲线：比较不同模型参数
- 学习曲线：比较不同规模训练集

5）超参数优化

- 网格搜索
- 随机搜索

# 深度学习总结

## 一、深度学习基础

### 1. 感知机、神经网络

#### 1）感知机

- 定义：又称“神经元”，接收多个输入，在线性函数作用下，产生输出。
- 功能：实现逻辑计算（单个感知机能实现AND/OR计算，多层感知机能实现XOR计算）；构成神经网络；具有自我学习能力。

#### 2）神经网络

- 定义：由多个神经元构成构成的互联有向无环网络结构
- 结构特点：输入层、隐藏层、输出层。每个神经元和下一层每个神经元相连接，同一层神经元不相连接。计算过程正向传播。又称“前馈神经网络”或“全连接网络”。
- 功能：通用近似定理证明，一个神经网络只需要包含一个隐藏层，这个隐藏层具有足够多的神经元，就可以以任意精度逼近任意连续函数。可以用作分类器、回归器。

### 2. 激活函数

1）作用：将神经网络/神经元的线性输出转换为非线性输出，从而更好逼近目标函数。

2）常用激活函数

- sigmoid：将负无穷~正无穷范围内的数压缩到0~1之间。优点：平滑、连续、容易求导；缺点：梯度消失。常用于二分类问题。
- tanh：均值为0，标准差为1，范围-1~1。优点：平滑、连续、容易求导，收敛速度快于sigmoid；缺点：梯度消失。常用于NLP中。
- relu：修正线性单元，计算简单、避免梯度消失。常用图像问题中。
- leak-relu：relu的变种，小于0的部分给一个很小的梯度。
- softmax：将神经网络计算的一组数值，转换为0~1相对概率，常用在分类器的输出层。

### 3. 损失函数与梯度下降

1）损失函数：度量预测值、真实值之间差异，用来评估模型优劣。

- 均方差：连续、回归问题中使用
- 交叉熵：离散、分类问题中使用

2）梯度下降

- 作用：通过寻找损失函数极小值，来寻找最优参数
- 原理：沿着损失函数梯度负方向，逐步调整参数，目的是找到损失函数极小值所在的点
- 更新法则：

$$
w_i = w_i + \Delta w_i \\
\Delta w_i = - \eta \frac{\partial E}{\partial w_i}
$$

- 导数偏导数：导数是函数变化率指标；如果一个函数有多个自变量，对其中某个自变量求导，称为偏导数
- 梯度下降法则
  - 随机梯度下降：随机选取一个样本执行训练，根据损失函数值执行梯度下降。计算速度快、收敛不稳定。
  - 批量梯度下降：选取所有样本执行训练，根据损失函数值执行梯度下降。计算速度慢、收敛稳定。
  - 小批量梯度下降：随机抽取batch_size个样本执行训练，根据损失函数值执行梯度下降。计算速度介于前两者之间，收敛稳定性也介于前两者之间。

3）梯度消失与梯度爆炸

- 梯度消失：梯度过小，导致模型不能进一步提升性能
- 梯度爆炸：梯度过大，导致模型不收敛

### 4. 反向传播算法

1）作用：求深度神经网络中隐藏层的偏导数

2）计算规则：加法节点，直接将上游传递的值传递给下游；乘法节点，上游传递过来的值乘以另一条边的值

3）链式求导法则：复合函数的求导（神经网络本质就是一个复杂的复合函数）

### 5. 卷积神经网络

1）卷积：两个函数在某个维度上的叠加

2）卷积神经网络（CNN）：加入了卷积层的神经网络，能够克服前馈神经网络的缺点：参数量大；深度受限；只能接受一维数据，破坏数据空间结构

3）一般结构：输入 --> 卷积/激活/池化 --> ... --> 全连接

- 卷积层：提取数据特征
  - 卷积运算：卷积核，在原始数据上挪动，每个对应位置上的值相乘后相加。涉及填充、步长、偏置、多通道卷积（每个通道卷积后的结果要进行合并）
  - 特点：一般来说，矩阵大小会改变（SAME模式除外），通道数会发生变化（有多少个卷积核，就输出多少个通道）
- 激活层：做激活运算
- 池化层：池化运算，降维、提高模型泛化能力
  - 池化类型：Max池化，Average池化，Sqrt池化
  - 特征：没有要学习的参数；通道数不发生变化；对微小的位置变化具有鲁棒性
- 全连接层：分类器、回归器

还有一些非标准层：

- dropout：丢弃学习，随机丢弃一部分神经元参数更新，从而防止过拟合
- Batch Normal：每层输入前，对数据进行归一化处理，可以防止梯度消失、防止过拟合、加快收敛速度、增加模型稳定性

4）经典CNN模型：LeNet, AlexNet, VGG, RestNet

# 计算机视觉

## 一、数字图像基础及预处理

### 1. 数字图像基础

1）图像存储方式：采样、量化将图像转换成离散的数字信号，灰度图像使用一个矩阵表示，彩色图像使用多通道表示

2）像素、灰度级（0~255）、灰度处理

3）色彩表示方式（色彩空间）：RGB（红色、绿色、蓝色）、HSV（色相、饱和度、亮度）、色彩空间转换

### 2.图像处理和变换

#### 1）色彩变换

- 灰度化：彩色图像转换为灰度图像，转换方式：分量法、平均值法、最大值法、加权平均法
- 通道操作
- 二值化、反二值化：设定预置，大于阈值设置为255，小于阈值设置为0，这种处理称为二值化；反之称为反二值化
- 直方图、直方图均衡化

#### 2）形态变换

- 镜像：水平镜像、垂直镜像
- 仿射变换：旋转、平移
- 缩放：放大插值法有最邻近插值法、双线性插值
- 图像加减：图像加法对两幅图像叠加；减法求两幅图像的差异
- 透视变换：将原坐标映射到新的坐标，经常用于图像形状矫正
- 腐蚀、膨胀、形态学梯度

#### 3）图像梯度

- 模板运算：模板卷积、模板排序
  - 中值模糊
  - 均值模糊
  - 高斯模糊
  - 图像锐化
- 边沿检测：拉普拉斯边沿检测、Sobel边沿检测、Canny边沿检测
- 轮廓：查找轮廓、绘制轮廓、绘制外接几何形状、多边形拟合

#### 4）数据增强

在现有样本基础之上，通过利用各种图像技术，得到新的样本



## 二、深度学习图像处理

1）手写体识别：利用全连接模型实现手写体数字识别

2）服饰识别：利用CNN实现图像分类

3）水果分类：构建数据集、数据预处理、样本标注、CNN搭建/训练/预测



## 三、CV高级

### 1. 目标检测

1）什么是目标检测：检测图像中有什么物体（分类问题），并对物体进行定位（回归问题）

2）目标检测两个系列

- 两阶段检测技术：先产生候选区，再做分类+回归；速度较慢、准确度较高。代表模型：R-CNN系列
- 一阶段检测技术：直接从特征图上产生分类+回归；速度较快、准确率较低。代表模型：YOLO系列、SSD、RetinaNet

3）目标检测原理

- 候选区域产生：滑动窗口法、Selective Search
- 数据表示：数据标注、检测结果可以表示一维向量，包括置信度、定位框参数(x,y,w,h)、类别信息(C1,C2,...,Cn的概率)
- 交并比（IOU）：评估定位框预测好坏，介于0~1之间的数字，越接近于1表示预测越好，越接近于0表示预测越差
- 非极大值抑制（NMS）：对于同一个目标物体的预测，保留置信度最高（或预测最好）的结果，去掉其它预测结果
- 多尺度检测：在不同大小特征图上进行预测

4）R-CNN系列：R-CNN、Fast R-CNN、Faster R-CNN

5）YOLO系列：YOLOv1, YOLOv2, YOLOv3

### 2. OCR

1）什么是OCR：光学字符识别，从图像中查找文字、识别文字的技术

2）一般步骤：输入 --> 文字检测 --> 文字识别 --> 输出

3）OCR和普通目标检测区别

- 检测对象不一样：OCR只检测文字
- 检测难度不一样：OCR检测难度高，通用目标检测难度较低
- 目标物体形状、比例不一样：文字一般是长矩形
- OCR特有的特点：多语种、多种排列检测、多角度检测

4）文字检测模型

- CTPN：适合检测水平文字
- SegLink：适合检测带角度文字

5）文字识别模型：CRNN+CTC

### 3. 人脸检测与人脸识别

1）人脸图像应用：人脸检测、人脸识别、人脸检索

2）人脸检测：MTCNN模型（P-NET、R-NET、O-NET）

3）单样本学习模型

- 孪生网络：具有两个相同结构、共享参数，每个网络对数据产生一个特征向量，通过比较特征向量欧氏距离，度量数据的相似性
- 三元神经网络：喂入三元组（参照样本、负样本、正样本）、三元损失函数

4）人脸识别模型

- DeepFace
- FaceNet

### 4. GAN

1）什么是GAN：是一种用于数据生成的模型，包含生成器、判别器两个子模型，通过两个子模型的对抗、博弈，训练出一个生成数据水平较高的生成器

2）结构：包含生成器、判别器。生成器主要生成假数据，尽量骗过判别器；判别器尽可能判断出真实样本、假数据

3）DCGAN模型

- 生成器：输入100维白噪声，生成器对输入数据进行层层反卷积（转置卷积）运算，输出生成的图像数据
- 判别器：本质上是二分类的图像分类器（真实样本、假数据），输入图像，对图像进行多次卷积运算，生成特征图，在特征图上产生预测结果（0/1）

## 四、项目与案例

### 1. 芯片质检

1）样本：芯片高清图像

2）技术路线：OpenCV图像技术

3）技术点：灰度化处理、二值化、模糊、膨胀、实心填充、图像算数运算、轮廓提取、实心填充

### 2. 胶囊质检

1）样本：胶囊产品高清图像

2）目标：利用图像技术检测胶囊良品与次品（气泡、大小头、黑斑、空胶囊）

3）技术路线：OpenCV图像技术

4）技术点：灰度化、二值化、模糊、膨胀、canny边沿提取、轮廓查找/绘制、利用像素计算轮廓与直线交点

### 3. 铁轨交叉点检测

1）样本：大量铁轨图像，采用目标检测标记工具进行标记

2）技术路线：OpenCV图像技术 + 深度学习

3）技术点：图像预处理、目标检测模型（YOLOv3）

### 4. 瓷砖检测

1）样本：1000多个瓷砖样本，包含6个类别的瑕疵（空洞、色斑、划痕、缺块、裂缝、其它）。对样本进行旋转、镜像，样本数量超过4万

2）数据预处理方式：灰度化、不切边旋转、镜像

3）模型：CNN（3组卷积池化+2组全连接）

4）关键参数：图像大小256*256，学习率0.0001~0.00001，批次大小16

5）效果：训练集下准确率超过99%，测试集下平均98%



### 5. 项目关键问题

1）如何构建数据集？

- 采集（收集）
- 数据清洗
- 数据分类存放，进行标注（分类、目标检测问题标注方式不一样）

2）数据从哪里来？

- 历史交易发生、积累的数据（价值最高）
- 购买
- 爬虫
- 采集

3）数据量多大？

- 使用深度学习模型，数据量越大越好
- 如果样本数据不足，可以采用数据增强方式，还可以采用特殊模型

4）项目采用什么模型？为什么？

- 根据项目需求，根据实际情况，以及问题的难易程度，首选现有的、成熟的、经典的模型
- 如果不确定使用哪个模型，可以比较选择综合性能更好的
- 在实际项目中，可以将多个模型配合使用，发挥各自特长

5）什么情况下使用OpenCV，什么情况下使用深度学习？

- OpenCV：样本较少、问题较简单、干扰因素少、场景相对单一、不需要理解图像内容
- 深度学习：样本数量充足、问题较复杂、干扰因素较多、场景多变、需要理解图像内容

6）数据如何标注？谁来标注？

- 数据标注：不同的问题采用不同标注方式
- 标注人员：
  - 技术人员自己标注
  - 专门图像标注人员
  - 有些情况下，需要专业人员进行标注

7）模型训练时间？

- 估算
- 增量训练方式

8）训练采用CPU还是GPU？GPU从哪里来？什么型号？

- 实际项目中绝大部分情况是在GPU上进行
- 购买企业级云主机，GPU按实际使用时间付费
- 查阅常用GPU型号、价格、主要参数

9）为什么不采用VGG/AlaxNet/ResNet？（效果）

10）项目准确率是多少？（实际中一般要达到95%以上）

11）模型如何部署、使用？

- 服务器端部署：部署在服务器上，由客户端发起远程调用
- 移动端部署：部署在手机、平板电脑移动终端的APP中进行检测
- 嵌入式设备部署
- 形式：封装网络服务、类、函数供客户端程序使用

12）项目关键问题

- 需求：谁用？用来做什么？解决什么问题？
- 数据集：来源、数量、预处理方式、标注
- 模型：模型选择、调参过程、优化手段
- 欠拟合、过拟合？处理方式？
- 效果：时间、精度







